# å®éªŒ 1 ä¿¡æ¯è·å–ä¸æ£€ç´¢åˆ†æ

æ–¹ç¾¿ PB19111647	ç†Šé¹ PB19111671	å¼ èˆ’æ’ PB19030888

## stage1. çˆ¬è™«

### å®éªŒè¦æ±‚

> é’ˆå¯¹ç»™å®šçš„ç”µå½±ã€ä¹¦ç± IDï¼Œçˆ¬å–å…¶è±†ç“£ä¸»é¡µï¼Œå¹¶è§£æå…¶åŸºæœ¬ä¿¡æ¯ã€‚
>
> a) å¯¹äºç”µå½±æ•°æ®ï¼Œè‡³å°‘çˆ¬å–å…¶åŸºæœ¬ä¿¡æ¯ã€å‰§æƒ…ç®€ä»‹ã€æ¼”èŒå‘˜è¡¨ï¼›
>
> b) å¯¹äºä¹¦ç±æ•°æ®ï¼Œè‡³å°‘çˆ¬å–å…¶åŸºæœ¬ä¿¡æ¯ã€å†…å®¹ç®€ä»‹ã€ä½œè€…ç®€ä»‹ï¼›
>
> c) çˆ¬è™«æ–¹å¼ä¸é™ï¼Œç½‘é¡µçˆ¬å–å’Œ API çˆ¬å–ä¸¤ç§æ–¹å¼éƒ½å¯ï¼Œä»‹ç»ä½¿ç”¨çš„çˆ¬è™«æ–¹å¼å·¥å…·ï¼›
>
> d) é’ˆå¯¹æ‰€é€‰å–çš„çˆ¬è™«æ–¹å¼ï¼Œå‘ç°å¹¶åˆ†æå¹³å°çš„åçˆ¬æªæ–½ï¼Œå¹¶ä»‹ç»é‡‡ç”¨çš„åº”å¯¹ç­–ç•¥ï¼›
>
> e) é’ˆå¯¹æ‰€é€‰å–çš„çˆ¬è™«æ–¹å¼ï¼Œä½¿ç”¨ä¸åŒçš„å†…å®¹è§£ææ–¹æ³•ï¼Œå¹¶æäº¤æ‰€è·å–çš„æ•°æ®ã€‚
>
> f) è¯¥é˜¶æ®µæ— è¯„æµ‹æŒ‡æ ‡è¦æ±‚ï¼Œåœ¨å®éªŒæŠ¥å‘Šä¸­è¯´æ˜çˆ¬è™«ï¼ˆåçˆ¬ï¼‰ç­–ç•¥å’Œè§£ææ–¹æ³•å³å¯ã€‚



### å®éªŒè®¾è®¡

æœ¬å®éªŒæ€»å…±åˆ†ä¸ºçˆ¬å–æ•°æ®+è§£ææ•°æ®ä¸¤ä¸ªé˜¶æ®µï¼Œå…·ä½“å¦‚ä¸‹ï¼š

#### ä¸€ã€çˆ¬å–æ•°æ®

##### é¡µé¢è·å–

æ•°æ®çˆ¬å–é‡‡ç”¨çš„æ˜¯ python çš„ requests åº“ï¼Œé€šè¿‡ç›´æ¥è¯·æ±‚å¯¹åº”çš„ url, è·å– html çš„å†…å®¹ã€‚

è¿™é‡Œä»¥ç”µå½±çˆ¬å–ä¸ºä¾‹ï¼Œæ¥è¯´æ˜å…·ä½“å®ç°è¿‡ç¨‹ï¼š

``` python
# è·å–å…·ä½“çš„ movie_id
id = movie_id[k]	
# æ ¹æ® movie_id æ„é€  url
url = "https://movie.douban.com/subject/" + id + "/"
# é€šè¿‡ request åº“è·å–å¯¹åº”çš„ html ç½‘é¡µå†…å®¹
response = requests.get(url,headers=headers)
content = response.content.decode('utf8')
```

##### åçˆ¬ç­–ç•¥

å¯¹äºæœªç™»å½•ç”¨æˆ·çš„ç½‘é¡µè¯·æ±‚ï¼Œ**è±†ç“£è§„å®šåŒä¸€ ip åœ°å€åœ¨ä¸€å®šæ—¶é—´å†…æœ€å¤šè¯·æ±‚100å¤šæ¬¡**ï¼›ä½†å¯¹äºç™»å½•çš„ç”¨æˆ·ï¼Œåˆ™æ²¡æœ‰è¿™ä¸€é™åˆ¶ã€‚

å› æ­¤æˆ‘ä»¬é‡‡å–çš„åçˆ¬ç­–ç•¥æ˜¯ï¼š**é€šè¿‡æºå¸¦ cookie è¿›è¡Œè¯·æ±‚ï¼Œæ¨¡æ‹Ÿç™»å½•è¿‡çš„ç”¨æˆ·ï¼Œä»è€Œç»•è¿‡è±†ç“£çš„é™åˆ¶ã€‚**å…·ä½“å®ç°ï¼š

- å…ˆé€šè¿‡æµè§ˆå™¨è·å¾—ç™»å½•åçš„ cookie
- åœ¨ header ä¸­æºå¸¦ cookie  æ•°æ®

``` python
headers = {
    "User-Agent": "Mozilla/5.0 (Windows NT 6.1; WOW64; rv:6.0) Gecko/20100101 Firefox/6.0",
    "Cookie": 'è¿™é‡Œæ˜¯ç™»å½•åçš„ç”¨æˆ·çš„cookie,å› ä¸ºå¾ˆé•¿,è¿™é‡Œå°±æ²¡ç›´æ¥ç²˜è´´ä¸Šæ¥'
}
```

#### äºŒã€è§£ææ•°æ®

åœ¨è·å–äº† html æ•°æ®åï¼Œä¸‹ä¸€æ­¥å°±æ˜¯ä» html ä¸­è·å–éœ€è¦çš„ä¿¡æ¯ã€‚è¿™é‡Œæˆ‘é‡‡ç”¨çš„æ˜¯**ç”¨ xpath è§£æ html æ–‡æ¡£**ï¼Œæ¥è·å–éœ€è¦çš„ä¿¡æ¯ã€‚

è¿™é‡Œä»¥ç”µå½±ä¸ºä¾‹ï¼Œè¯´æ˜å…·ä½“è¿‡ç¨‹ï¼š

``` python
# ç”¨ä¸€ä¸ªå­—å…¸æ¥å­˜ç”µå½±ä¿¡æ¯
movie = {"id":id,"ç”µå½±å":"","åŸºæœ¬ä¿¡æ¯":"","å‰§æƒ…ç®€ä»‹":"","æ¼”èŒå‘˜":"","è±†ç“£è¯„åˆ†":""}
# è§£æ html æ–‡æ¡£
html = etree.HTML(content)
# è·å–ç”µå½±å
title = html.xpath('//*[@id="content"]/h1/span/text()')
for str in title:
    movie["ç”µå½±å"] += str
# è·å–è¯„åˆ†ä¿¡æ¯
rating = html.xpath('//div[@class="rating_self clearfix"]//strong/text()')
if len(rating):
    movie["è±†ç“£è¯„åˆ†"] += html.xpath('//div[@class="rating_self clearfix"]//strong/text()')[0]
else:   # ã€Šå»ºå›½å¤§ä¸šã€‹ç­‰ç”µå½±ç¦æ­¢è¯„åˆ†
    movie["è±†ç“£è¯„åˆ†"] = "æš‚æ— è¯„åˆ†"
# è·å–åŸºæœ¬ä¿¡æ¯
info = html.xpath('//*[@id="info"]/span/text() | //*[@id="info"]/span//a/text() | //*[@id="info"]
for str in info:
    if str[0] == '\n':
        movie["åŸºæœ¬ä¿¡æ¯"] += '\n'
    else:
        movie["åŸºæœ¬ä¿¡æ¯"] += str
# è·å–å®Œæ•´çš„ç®€ä»‹
intro = html.xpath('//span[@class="all hidden"]/text()')
if len(intro) == 0:
    intro = html.xpath('//span[@property="v:summary"]/text()')
for str in intro:
    str = str.strip("\n").strip(" ").strip("\n")
    movie["å‰§æƒ…ç®€ä»‹"] += str + '\n'
# è·å–æ¼”èŒå‘˜è¡¨
stuff = html.xpath('//li[@class="celebrity"]//span/text() | //li[@class="celebrity"]//span//a/tex
for i, str in enumerate(stuff):
    movie["æ¼”èŒå‘˜"] += str + " "
    if i % 2 != 0 :
        movie["æ¼”èŒå‘˜"] += "\n"
```



### ç»“æœå±•ç¤º

- å…·ä½“ä»£ç è¯¦è§ `stage1/catch_book.py` å’Œ `stage1/catch_movie.py` 

- ç”µå½±å’Œä¹¦ç±çš„çˆ¬å–è¯¦ç»†ç»“æœè§ï¼š`stage1/data/movie.csv` å’Œ `stage1/data/book.csv`

- è¿™é‡Œä»…å±•ç¤ºéƒ¨åˆ†æˆªå›¾

  <center>
      <img style="border-radius: 0.
  3125em;
      box-shadow: 0 2px 4px 0 rgba
  (34,36,38,.12),0 2px 10px 0 
  rgba(34,36,38,.08);
      zoom: 35%;"  
      src="./figs/01.png">
      <br>
      <div style="color:orange; 
  border-bottom: 1px solid 
  #d9d9d9;
      display: inline-block;
      color: #999;
      padding: 2px;">ç”µå½±çˆ¬å–ç»“æœ</div>
  </center>

<center>
    <img style="border-radius: 0.
3125em;
    box-shadow: 0 2px 4px 0 rgba
(34,36,38,.12),0 2px 10px 0 
rgba(34,36,38,.08);
    zoom: 35%;"  
    src="./figs/02.png">
    <br>
    <div style="color:orange; 
border-bottom: 1px solid 
#d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">ä¹¦ç±çˆ¬å–ç»“æœ</div>
</center>




## stage 2. å¸ƒå°”æ£€ç´¢

### å®éªŒè¦æ±‚

>åŸºäºç¬¬ä¸€é˜¶æ®µçˆ¬å–çš„è±†ç“£ Movie/Book ä¿¡æ¯ï¼Œå®ç°ç”µå½±æˆ–ä¹¦ç±çš„æœç´¢å¼•æ“ã€‚å¯¹äºç»™å®šçš„æŸ¥è¯¢ï¼Œèƒ½å¤Ÿä»¥ç²¾ç¡®æŸ¥è¯¢æˆ–æ¨¡ç³Šè¯­ä¹‰åŒ¹é…çš„æ–¹æ³•è¿”å›æœ€ç›¸å…³çš„ä¹¦ç±æˆ–è€…ç”µå½±é›†ã€‚
>
>**1. å¯¹ä¸€é˜¶æ®µä¸­çˆ¬å–çš„ç”µå½±å’Œä¹¦ç±æ•°æ®è¿›è¡Œé¢„å¤„ç†ï¼Œå°†æ–‡æœ¬è¡¨å¾ä¸ºå…³é”®è¯é›†åˆ**
>
>**2. åœ¨ç»è¿‡é¢„å¤„ç†çš„æ•°æ®é›†ä¸Šå»ºç«‹å€’æ’ç´¢å¼•è¡¨**ğ‘º**ï¼Œå¹¶ä»¥åˆé€‚çš„æ–¹å¼å­˜å‚¨ç”Ÿæˆçš„å€’æ’ç´¢å¼•æ–‡ä»¶**
>
>**3. å¯¹äºç»™å®šçš„ bool æŸ¥è¯¢ï¼Œæ ¹æ®ä½ ç”Ÿæˆçš„å€’æ’ç´¢å¼•è¡¨ï¼Œè¿”å›ç¬¦åˆæŸ¥è¯¢è§„åˆ™çš„ç”µå½±æˆ–/å’Œä¹¦ç±é›†åˆå¹¶ä»¥åˆé€‚çš„æ–¹å¼å±•ç°ç»™ç”¨æˆ·**

### å®éªŒè®¾è®¡

#### ä¸€ã€åˆ†è¯

åˆ†è¯ä½¿ç”¨äº†ç»“å·´åˆ†è¯åº“ï¼ŒåŒæ—¶äººå·¥æå–äº†ä¸€äº›å¦‚ äººåã€ç”µå½±åä¹‹ç±»çš„ç‰¹æ®Šåè¯ï¼ŒåŠ å…¥åˆ°ç»“å·´åˆ†è¯çš„äººå·¥å­—å…¸ä¸­ï¼Œå¸®åŠ©æ›´å¥½çš„åˆ†è¯ã€‚

è¿™é‡Œä»¥ç”µå½±ä¸ºä¾‹ï¼Œè¯´æ˜å…·ä½“çš„å®ç°ï¼š

``` python
movie_data = pd.read_csv("./data/movie.csv")
movie_tag = pd.read_csv("./data/Movie_tag.csv")
col_name = ['id', 'words']
movie_words = []
# è¯»å–æ¯ä¸ªç”µå½±
for _,movie in tqdm(movie_data.iterrows(), total=movie_data.shape[0], leave=False):
    # å¯¹ç”µå½±çš„åŸºæœ¬ä¿¡æ¯ã€æ¼”èŒå‘˜è¡¨ç­‰è¿›è¡Œåˆ†è¯
    key_words = split_movie(movie)
    # è¯»å–ç”µå½±çš„ tag 
    tags = list(movie_tag.loc[movie_tag['id'] == movie['id']]['tag'])[0]
    tag_words = set(str(tags).split(","))
    key_words = set.union(key_words, tag_words)
    key_words = key_words - stopwords
    # å­˜æ¯ä¸ªç”µå½±çš„åˆ†è¯ç»“æœ
    movie_words.append({'id': movie['id'], 'words': key_words})
# å°†åˆ†è¯ç»“æœå­˜ä¸‹æ¥ï¼Œæ–¹ä¾¿ä¸‹ä¸€ä½åŒå­¦ä½¿ç”¨
pd.DataFrame(movie_words,columns=col_name).to_csv("./data/movie_words.csv",index=False)
with open("./data/word_dict.pkl","wb") as f:
    pickle.dump(word_dict,f)
print("split movie finish!")
```

å…·ä½“çš„ç”µå½±åˆ†è¯å‡½æ•°å¦‚ä¸‹ï¼š

``` python
def split_movie(movie):
    key_words = set()
    # ç”µå½±IDä½œä¸ºä¸€ä¸ªè¯
    key_words.add(str(movie['id']))
    # ç”µå½±åçš„åˆ†è¯
    name = str(movie['ç”µå½±å'])
    idx = name.find("(")
    if idx != -1:  # åˆ é™¤åé¢çš„å¹´ä»½
        key_words.add(name[idx + 1:-1])
        name = name[:idx]
    chinese, english = split_English(name)  # ä¿ç•™è‹±æ–‡åçš„å®Œæ•´æ€§
    if len(english) != 0:
        key_words.add(english)
    for word in chinese.split():  # å¯¹äºéŸ©æ–‡å’Œæ—¥æ–‡ç­‰æ²¡æœ‰å¤„ç†
        key_words.add(word)
    # ç”µå½±åŸºæœ¬ä¿¡æ¯ã€æ¼”èŒå‘˜è¡¨ã€å‰§æƒ…ç®€ä»‹çš„åˆ†è¯
    info = str(movie['åŸºæœ¬ä¿¡æ¯'])
    stuff = str(movie['æ¼”èŒå‘˜'])
    intro = str(movie['å‰§æƒ…ç®€ä»‹'])
    key_words = set.union(key_words, split_movie_stuff(stuff))
    key_words = set.union(key_words, split_movie_info(info))
    for word in key_words:
        word = str(word)
        jieba.add_word(word)
        word_dict.append(word)
    key_words = set.union(key_words, set(jieba.cut_for_search(intro)))
    for word in key_words:
        word = str(word)
        jieba.del_word(word)
    return key_words
```

#### äºŒã€å»ºç«‹å€’æ’è¡¨

è¯»å–æ¯éƒ¨ç”µå½±æˆ–ä¹¦ç±ç®€ä»‹çš„åˆ†è¯ç»“æœï¼Œç»Ÿè®¡å‡ºæ‰€æœ‰çš„è¯é¡¹

```python
def read_csv():
    book_data = pd.read_csv("../data/book_words.csv", dtype={'id': int, 'words': str})
    # print(book_data.head())
    data = book_data
    words_all_book = set()
    book = dict()
    for i in range(len(data)):
        words_a_book = eval(data['words'][i])
        book[data['id'][i]] = words_a_book
        words_all_book = words_all_book.union(words_a_book)
```

éå†æ¯ä¸ªè¯é¡¹ï¼Œç»Ÿè®¡å‡ºç°è¯¥è¯é¡¹çš„æ–‡æ¡£é›†åˆï¼ŒæŒ‰ç…§æ–‡æ¡£ç¼–å·å‡åºæ’åˆ—ï¼Œç”Ÿæˆå€’æ’è¡¨ã€‚å¯¹äºé•¿åº¦è¶…è¿‡ä¸€å®šé˜ˆå€¼çš„å€’æ’è¡¨ç”Ÿæˆå•å±‚å®šé•¿çš„è·³è¡¨æŒ‡é’ˆåºåˆ—ã€‚

```python
def gen_invert_table():
    invert_index = []
    words_all_book, book, words_all_movie, movie = read_csv()
    for b in words_all_book:
        temp = []
        skip_table = []
        for j in book.keys():
            field = book[j]
            if b in field:
                temp.append(j)
        temp_sorted = sorted(temp)
        len1 = len(temp_sorted)
        if len1 == 1 or len1 == 2:
            for i in range(len1):
                skip_table.append({'index': None, 'value': None})
        else:
            for i in range(len1):
                if i % 2 == 0 and i < len1 - 2:
                    skip_table.append({'index': i + 2, 'value': temp_sorted[i + 2]})
                else:
                    skip_table.append({'index': None, 'value': None})

        invert_index.append({'word': b, 'id_list': temp_sorted, 'skip_table': skip_table})
    pd.DataFrame(invert_index, columns=['word', 'id_list', 'skip_table']).to_csv("../data/book_invert.csv", index=False)
```

#### ä¸‰ã€å¸ƒå°”æŸ¥è¯¢

> â€‹		å¯¹äºç»™å®šçš„ `bool` æŸ¥è¯¢ $\text{Q}_\text{bool}$ ï¼Œæ ¹æ®ç”Ÿæˆçš„å€’æ’ç´¢å¼•è¡¨ Sï¼Œè¿”å›ç¬¦åˆæŸ¥è¯¢è§„åˆ™çš„ç”µå½±æˆ–ä¹¦ç±é›†åˆï¼Œå¹¶ä»¥åˆé€‚çš„æ–¹å¼å±•ç°ç»™ç”¨æˆ·ï¼Œç»™å‡ºç”µå½±åç§°å’Œåˆ†ç±»æˆ–éƒ¨åˆ†ç®€ä»‹ã€‚

##### **step1. ä¸­ç¼€å¸ƒå°”è¡¨è¾¾å¼è½¬åç¼€å¸ƒå°”è¡¨è¾¾å¼**

**è¾“å…¥å¸ƒå°”è¡¨è¾¾å¼ï¼Œé¦–å…ˆå¯¹å…¶è¿›è¡Œå¤„ç†ï¼Œä½¿ä»–è®¡ç®—æ¬¡åºç¬¦åˆ `AND`, `OR`, `NOT` çš„è¿ç®—æ¬¡åºï¼Œä¾‹å¦‚ `A OR B AND C` è®¡ç®—çš„æ¬¡åºä¸º `A OR (B AND C)`ã€‚**

å‡è®¾è¾“å…¥éƒ½æ˜¯åˆæ³•çš„ï¼Œå…ˆå°†è¾“å…¥çš„ä¸­ç¼€å¸ƒå°”è¡¨è¾¾å¼è½¬åŒ–æˆåç¼€å¸ƒå°”è¡¨è¾¾å¼ï¼Œä¾‹å¦‚ A AND B è½¬æ¢æˆ A B AND

å…·ä½“æ­¥éª¤å¦‚ä¸‹ï¼š

0. è®¾ç«‹äº†ä¸¤ä¸ªæ ˆï¼Œåˆ†åˆ«å­˜å‚¨ `æ“ä½œç¬¦` å’Œ `å­—ç¬¦`

1. å¯¹äºè¾“å…¥çš„è¯­å¥ï¼Œæœç´¢ `AND` ï¼Œ`OR`ï¼Œ`NOT`ï¼Œ`(`ï¼Œ`)` æ‰€åœ¨çš„ä½ç½®

   - å¦‚æœéƒ½ä¸å‡ºç°åœ¨è¯­å¥ä¸­ï¼Œè¯´æ˜è¯­å¥å¤„ç†å®Œæ¯•ï¼Œè·³è½¬åˆ° 4

2. åˆ¤æ–­æœå¯»åˆ°çš„æ“ä½œç¬¦æ˜¯å¦æ»¡è¶³ä¸‹åˆ—æƒ…å†µ

   - `(`æˆ–è€… `æ“ä½œç¬¦æ ˆ`ä¸ºç©ºï¼š
     - ç›´æ¥å°†æ“ä½œç¬¦åŠ å…¥å¯¹åº”æ ˆä¸­ï¼Œå¹¶æ ¹æ®æ“ä½œç¬¦ç±»å‹é€‰æ‹©æ˜¯å¦å°†æ“ä½œç¬¦å‰æ–¹ä¸´è¿‘çš„å­—ç¬¦åŠ å…¥å­—ç¬¦æ ˆä¸­

   - `AND`ï¼Œ`OR` æ—¶ç›´æ¥æ·»åŠ 

   - å¦‚æœ æ ˆé¡¶ çš„æ“ä½œç¬¦ä¼˜å…ˆçº§é«˜äºæœå¯»åˆ°çš„æ“ä½œç¬¦ä¼˜å…ˆçº§

     - å¦‚æœè¯¥æ“ä½œç¬¦æ˜¯ `)`
       - å°†æ“ä½œç¬¦æ ˆçš„å­—ç¬¦ `pop` åˆ° å­—ç¬¦æ ˆä¸­ï¼Œç›´åˆ° `(` 

     - å¦åˆ™ï¼Œå°†æ“ä½œç¬¦æ ˆ `pop` åˆ°å­—ç¬¦æ ˆä¸­ï¼Œç›´åˆ°ä¸æ»¡è¶³ä¸Šè¿°æ¡ä»¶

3. å…¶ä»–æƒ…å†µï¼Œåˆ™ç›´æ¥å°†æ“ä½œç¬¦å‹å…¥æ ˆä¸­ï¼Œå¹¶æ ¹æ®æ“ä½œç¬¦ç±»å‹é€‰æ‹©æ˜¯å¦å°†æ“ä½œç¬¦å‰æ–¹ä¸´è¿‘çš„å­—ç¬¦åŠ å…¥å­—ç¬¦æ ˆä¸­

4. å¸ƒå°”æŸ¥è¯¢è¯­å¥å­—ç¬¦å¤„ç†å®Œæ¯•ï¼Œå°†æ“ä½œç¬¦æ ˆä¸­å‰©ä½™çš„æ‰€æœ‰æ“ä½œç¬¦å‹å…¥å­—ç¬¦æ ˆä¸­

##### **step2. è®¡ç®—åç¼€è¡¨è¾¾å¼**

â€‹		æ–°å»ºç«‹äº†ä¸€ä¸ªæ ˆï¼Œå­˜å‚¨å¸ƒå°”è¡¨è¾¾å¼ä¸­é—´è¿‡ç¨‹å’Œæœ€ç»ˆçš„è®¡ç®—ç»“æœ

`element_stack` ä¸ºä¸Šé¢æœ€ç»ˆå¾—åˆ°çš„å­—ç¬¦æ ˆï¼Œ`calcula_stack` å­˜å‚¨ä¸­é—´è¿‡ç¨‹çš„è®¡ç®—ç»“æœ

```python
calculate_stack = []
for i in range(0, len(element_stack)):
    if element_stack[i] != "NOT" and element_stack[i] != "AND" and element_stack[i] != "OR":
        calculate_stack.append(element_stack[i])
    elif element_stack[i] == "AND":
        elem2 = calculate_stack.pop()
        elem1 = calculate_stack.pop()
        calculate_stack.append(AndOperator(elem1, elem2))
    elif element_stack[i] == "OR":
        elem2 = calculate_stack.pop()
        elem1 = calculate_stack.pop()
        calculate_stack.append(OrOperator(elem1, elem2))
    else:
        elem1 = calculate_stack.pop()
        calculate_stack.append(NotOperator(id_all, elem1))
```

##### **step3. å¸ƒå°”æ£€ç´¢**

â€‹		æˆ‘ä»¬åœ¨ç¬¬ä¸€éƒ¨åˆ† `å¸ƒå°”è¡¨è¾¾å¼ä¸­ç¼€è½¬åç¼€` å·²ç»æŠŠæ¯ä¸€ä¸ªè¯åˆ†ç¦»å‡ºæ¥äº†ï¼Œæˆ‘ä»¬è¿›è¡Œ `AND`, `OR`, `NOT` æ“ä½œæ—¶ï¼Œåªéœ€è¦å°†è¿™ä¸ªè¯å¯¹åº”çš„å€’æ’è¡¨è¿›è¡Œ `AND`, `OR`, `NOT` æ“ä½œå³å¯ã€‚

> â€‹		èµ·åˆï¼Œæˆ‘ä»¬æƒ³å…ˆè°ƒç”¨è¿‘ä¹‰è¯åº“ï¼Œå…ˆæŠŠåˆ†ç¦»å‡ºçš„æ¯ä¸ªè¯å…ˆæ‰¾ä»–ä¸´è¿‘çš„è¿‘ä¹‰è¯ï¼Œå…ˆæŠŠè¿™äº›è¯çš„å€’æ’è¡¨åˆå¹¶ï¼Œå†è¿›è¡ŒæŸ¥è¯¢è¯­å¥çš„å¸ƒå°”è¿ç®—ï¼Œä½†æ˜¯ `synonyms` åº“çš„æ•ˆæœä¸å°½äººæ„ï¼Œæ‰€ä»¥æˆ‘ä»¬åœ¨å¸ƒå°”æŸ¥è¯¢é‡Œé¢æ²¡æœ‰ä½¿ç”¨è¿‘ä¹‰è¯åº“ã€‚

â€‹		`AND` å¯¹åº”å€’æ’è¡¨è¿ç®—ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†è·³è¡¨æŒ‡é’ˆè¿›è¡Œåˆå¹¶ã€‚

```python
# ([1007433],[{'index': None, 'value': None}])
# table ä¸ºä¸Šè¿°ç»“æ„, å…ƒç»„å†…ç¬¬ä¸€ä¸ªå…ƒç´ ä¸º id åˆ—è¡¨, ç¬¬äºŒä¸ªå…ƒç´ ä¸ºè¯¥ id å¯¹åº”çš„è·³è¡¨æŒ‡é’ˆ
# index, value æ˜¯ä¸‹æ ‡å’Œä¸‹æ ‡å¯¹åº”çš„ id å€¼
def AndOperator(table1, table2):
    if table1 == () or table2 == ():
        return ()
    result = []
    i = j = 0
    while i < len(table1[0]) and j < len(table2[0]):
        # ä¸¤ä¸ª list ç›¸ç­‰ï¼Œåˆ™åˆå¹¶åˆ°æ–°è¡¨ä¸­
        if table1[0][i] == table2[0][j]:
            result.append(table1[0][i])
            i += 1
            j += 1
        elif table1[0][i] < table2[0][j]:
            # åˆ¤å®šè®°å½•æ˜¯å¦å­˜åœ¨è·³è¡¨æŒ‡é’ˆä»¥åŠè·³è¡¨æŒ‡é’ˆçš„åç»­ id æ˜¯å¦å°äºå½“å‰åˆ¤å®šçš„åˆ—è¡¨ id
            # æ»¡è¶³ï¼Œåˆ™è·³è½¬ï¼Œå¦åˆ™ä¸è·³
            while table1[1][i]['index'] is not None and table1[1][i]['value'] < table2[0][j]:
                i = table1[1][i]['index']
            else:
                i += 1
        else:# åŒç†
            while table2[1][j]['index'] is not None and table2[1][j]['value'] < table1[0][i]:
                j = table2[1][j]['index']
            else:
                j += 1
    return generate_table(result)
```

â€‹		`OR` è¿ç®—ä»£è¡¨çš„æ˜¯å€’æ’è¡¨çš„å¹¶é›†è¿ç®—ï¼Œæˆ‘ä»¬è¿™é‡Œé‡‡ç”¨çš„æ˜¯ç›´æ¥ä½¿ç”¨ `set` é›†åˆçš„æˆ–è¿ç®—è¿›è¡Œåˆå¹¶ã€‚

â€‹		å¾—åˆ°æ–°è¡¨åï¼Œé‡æ–°æ’å…¥è·³è¡¨æŒ‡é’ˆ

```python
def OrOperator(table1, table2):
    if table1 == ():
        return table2
    elif table2 == ():
        return ()
    result = set(table1[0]) | set(table2[0])
    # æ’åº
    result = sorted(list(result))
    # é‡æ–°ç”Ÿæˆè·³è¡¨æŒ‡é’ˆ
    return generate_table(result)
```

â€‹		`NOT` è¿ç®—æ˜¯å°†å…¨éƒ¨ id å‡å» å¯¹åº”è¯çš„ id åˆ—è¡¨ï¼Œæˆ‘ä»¬è¿™é‡Œé‡‡ç”¨çš„æ˜¯ç›´æ¥ä½¿ç”¨ `set` é›†åˆçš„è¡¥è¿ç®—è¿›è¡Œåˆå¹¶ã€‚

â€‹		å¾—åˆ°æ–°è¡¨åï¼Œé‡æ–°æ’å…¥è·³è¡¨æŒ‡é’ˆã€‚

```python
def NotOperator(id_all, table):
    if table == ():
        return generate_table(id_all)
    result = set(id_all) - set(table[0])
    result = sorted(list(result))
    return generate_table(result)
```

#### å››ã€è‡ªç„¶è¯­è¨€æŸ¥è¯¢

å…ˆå¯¹è¾“å…¥çš„è¯­å¥è¿›è¡Œåˆ†è¯å¤„ç†ï¼Œè°ƒç”¨ç¬¬ä¸€éƒ¨åˆ†æ‰€å†™çš„åˆ†è¯å‡½æ•°ï¼Œåˆ†è¯ä¹‹åè°ƒç”¨è¿‘ä¹‰è¯åº“ï¼Œå°†è¿‘ä¹‰è¯å¯¹åº”çš„å€’æ’è¡¨åˆå¹¶ï¼Œä¹‹åå†ç»Ÿè®¡æ¯ä¸ªåˆ†è¯ä¸­å¯¹åº”å€’æ’è¡¨ id å‡ºç°çš„æ¬¡æ•°ï¼Œå°†å…¶æ’åºã€‚

##### step1. åˆ†è¯ï¼Œæ‰¾è¿‘ä¹‰è¯

```python
# å¯¹è¾“å…¥çš„è¯­å¥è¿›è¡Œåˆ†è¯å¤„ç†å¹¶å¾—åˆ°æ¯ä¸ªè¯ç›¸åº”çš„è¿‘ä¹‰è¯
# è¿™é‡Œåªé€‰å–äº†ç¬¬ä¸€ä¸ªæœ€ç›¸è¿‘çš„è¿‘ä¹‰è¯è¿›è¡Œå¤„ç†
def GetMovieSynonymWords() -> list[tuple]:
    sentence = input("è¯·è¾“å…¥æŸ¥è¯¢çš„è¯­å¥")
    useless_keywords = {'å¯¼æ¼”', 'ç¼–å‰§', 'ä¸»æ¼”', 'ç±»å‹', 'åˆ¶ç‰‡å›½å®¶/åœ°åŒº', 'åˆå', 'IMDb', 'è¯­è¨€'}
    util = utils()
    words = util.split(sentence)
    # å°†åœç”¨è¯å»é™¤
    words = words - useless_keywords
    print(words)
    synonym_words = []
    for word in words:
        if synonyms.nearby(word) != ([], []):
            synonym_words.append((word, synonyms.nearby(word)[0][1]))
        else:
            synonym_words.append((word, word))
    return synonym_words
```

##### step2. åˆå¹¶è¿‘ä¹‰è¯çš„å€’æ’è¡¨

```python
# å°†è¿‘ä¹‰è¯çš„ IdList è¿›è¡Œåˆå¹¶
# words: åˆ†å¥½çš„è¯é›†åˆ
# è¿™é‡Œè¿”å›çš„è¾“å…¥çš„è¯­å¥æ˜¯åˆ†è¯ä¹‹åçš„ id_list
# è¿”å›å­—å…¸ï¼škey: word, value: id
def Generate_Word_List(words: list[tuple]) -> dict:
    file_name = "../../data/movie_invert.csv"
    # å­˜å‚¨å€’æ’ç´¢å¼•è¡¨æ‰€æœ‰çš„æ•°æ®
    dic = {}
    # å­˜å‚¨æŸ¥è¯¢è¯­å¥åˆ†è¯ä¹‹åçš„ç´¢å¼•æ•°æ®
    query_WordId_dic = {}
    with open(file_name, encoding="utf8", mode='r') as f:
        csv_reader = csv.reader(f)
        # ä»ç¬¬äºŒè¡Œå¼€å§‹è¯»å–
        next(csv_reader)
        # å°†ç¬¬äºŒä¸ªå­—ç¬¦ä¸²è½¬ä¸ºåˆ—è¡¨
        # åˆ—è¡¨ä¸­å«æœ‰çš„æ˜¯ id å­—æ®µ
        for row in csv_reader:
            dic[row[0]] = eval(row[1])
            # print(type(dic[row[0]][0]))
    # print(dic)
    # å°† ä¸¤ä¸ª/å¤šä¸ª è¿‘ä¹‰è¯çš„ id_list åˆå¹¶
    for synonym_word in words:
        print(synonym_word)
        for i in range(0, len(synonym_word), 2):
            if synonym_word[i] in dic.keys() and synonym_word[i + 1] in dic.keys():
                print(synonym_word[i], synonym_word[i + 1])
                query_WordId_dic[synonym_word[i]] = Or_MergeIndexTable(dic[synonym_word[i]], dic[synonym_word[i + 1]])
                print(query_WordId_dic)
            elif synonym_word[i] in dic.keys():
                query_WordId_dic[synonym_word[i]] = dic[synonym_word[i]]
            elif synonym_word[i + 1] in dic.keys():
                query_WordId_dic[synonym_word[i]] = dic[synonym_word[i + 1]]
            else:
                query_WordId_dic[synonym_word[i]] = []
    return query_WordId_dic
```

##### step3. è‡ªç„¶è¯­è¨€æ£€ç´¢

```python
# è‡ªç„¶è¯­è¨€å¤„ç†å‡½æ•°
# å¤„ç†å·²ç»å¾—åˆ°çš„è¯å¯¹åº”çš„ id åˆ—è¡¨
# ç»Ÿè®¡å„ id å‡ºç°çš„æ¬¡æ•°
# å¹¶å°†å…¶è¿›è¡Œæ’åºè¾“å‡º
def Natural_language_process() -> None:
    # è®°å½•æŸ¥è¯¢è¯­å¥ä¸­å‡ºç°çš„è¯ ä»¥åŠå¯¹åº”çš„ id åˆ—è¡¨
    query_dict = {}
    synonym_words = GetMovieSynonymWords()
    query_dict = Generate_Word_List(synonym_words)
    # è®°å½•æ¯ä¸€ä¸ª id å‡ºç°çš„æ¬¡æ•°
    id_dict = {}
    # éå†å­—å…¸ä¸­çš„æ¯ä¸€ä¸ªè¯
    for word in query_dict:
        id_list = query_dict[word]
        # éå†è¯å¯¹åº”ä¸­ id_list æ¯ä¸€ä¸ª id
        # å¹¶è®°å½• id å‡ºç°çš„æ¬¡æ•°
        for id in id_list:
            if id in id_dict.keys():
                id_dict[id] += 1
            else:
                id_dict[id] = 1
    # è¾“å‡ºæ’åºåçš„ç»“æœ
    print(sorted(id_dict.items(), key=lambda x: x[1], reverse=True))
```

### ç»“æœå±•ç¤º

#### bool æŸ¥è¯¢çš„ç»“æœ

![](./figs/03.png)

![](./figs/07.png)

![](./figs/08.png)

#### è‡ªç„¶è¯­è¨€æŸ¥è¯¢ç»“æœ

![](figs/06.png)



## stage 3. æ¨è

### å®éªŒè¦æ±‚

> åœ¨è¿™æ¬¡å®éªŒä¸­ï¼Œä½ ä»¬éœ€è¦è‡ªè¡Œåˆ’åˆ†è®­ç»ƒé›†ä¸æµ‹è¯•é›†ï¼Œåœ¨æµ‹è¯•é›†ä¸Šä¸ºç”¨æˆ·å¯¹ä¹¦ç±æˆ–ç”µå½±çš„è¯„åˆ†è¿›è¡Œæ’åºï¼Œå¹¶ç”¨ NDCG å¯¹è‡ªå·±çš„é¢„æµ‹ç»“æœè¿›è¡Œè¯„åˆ†å’Œè¿›ä¸€æ­¥åˆ†æã€‚

### å®éªŒè®¾è®¡

#### ä¸€ã€MF æ¨¡å‹ä»‹ç»

1. æœ¬æ­¤å®éªŒï¼Œä½¿ç”¨äº†çŸ©é˜µåˆ†è§£æ¨¡å‹ (MF) æ¥é¢„æµ‹ user å¯¹ item çš„è¯„åˆ†ã€‚

2. **æ¨¡å‹è¯´æ˜**

   MFï¼ˆçŸ©é˜µåˆ†è§£ï¼‰æ˜¯ä¸€ç§ latent factor models ï¼Œå®ƒæ ¹æ® user-item çš„è¯„åˆ†çŸ©é˜µï¼ˆé«˜åº¦ç¨€ç–åŒ–ï¼‰ï¼Œæ„å»º user å’Œ item çš„å‘é‡ã€‚

3. **å‚æ•°è¯´æ˜**

   MF æ¨¡å‹å°† user å’Œ item æ˜ å°„åˆ°ä¸€ä¸ª f ç»´çš„ latent factor ç©ºé—´ï¼Œç”¨å†…ç§¯è¡¨ç¤º user-item äº’åŠ¨ã€‚å³ï¼š

   item_i è¡¨ç¤ºä¸º $q_i \in \mathbb{R}^f$ ï¼Œè¡¨ç¤º item_i å«æœ‰è¿™äº› factor çš„ç¨‹åº¦

   user_i è¡¨ç¤ºä¸º $p_u \in \mathbb{R}^f$ ,  è¡¨ç¤º user_i å–œçˆ±è¿™äº› factor çš„ç¨‹åº¦

   $\hat{r}_{ui} = q_i^Tp_u$ , è¡¨ç¤º user å¯¹ item çš„è¯„åˆ†çš„é¢„æµ‹å€¼

4. **è€ƒè™‘è¯¯å·®**

   è€ƒè™‘è¯„åˆ†æ—¶ä¸åŒ user å’Œ item çš„è¯¯å·®ï¼Œå¯ä»¥å°†è¯„åˆ†æ‹†è§£ä¸º 4 ä¸ªéƒ¨åˆ†ï¼šglobal average**ï¼ˆ$\mu$ï¼‰**, item bias **ï¼ˆ$b_i$ï¼‰**, user bias**ï¼ˆ$b_u$ï¼‰**, user-item iteraction **ï¼ˆ$q_i^Tp_u$)**ã€‚

   ä¸¾ä¸ªä¾‹å­ï¼Œå‡è®¾æ‰€æœ‰ç”µå½±çš„å¹³å‡æ‰“åˆ†æ˜¯ 3.7ï¼Œã€ŠTitanicã€‹å¾ˆå¥½ï¼Œå®ƒçš„è¯„åˆ†ä¼šæ¯”åŒé¢˜æå¹³å‡åˆ†é«˜ï¼Œå…¶ item bias æ˜¯ 0.5ï¼Œ è€Œ Joe æ˜¯ä¸€ä¸ªä¸¥æ ¼çš„äººï¼Œå…¶æ‰“åˆ†åä½ï¼Œuser bias ä¸º -0.3ã€‚é‚£ä¹ˆ Joe å¯¹ Titanic è¯„åˆ†ä¸ºï¼š3.7 + 0.5 - 0.3 + $q_i^Tp_u$ ã€‚

5. **è¯„åˆ†é¢„æµ‹**

   user å¯¹ item çš„è¯„åˆ†å¯ä»¥è¡¨ç¤ºä¸ºï¼š
   $$
   \hat{r}_{ui}(t) = \mu + b_u(t) +q_i^Tp_u(t)
   $$

6. **ä¼˜åŒ–ç›®æ ‡**
   $$
   \min _{p^* , q^* , b^*} \sum_{(u, i) \in \mathrm{K}}\left(r_{u i}-\mu-b_{u}-b_{i}-p_{u}^{T} q_{i}\right)^{2}
   $$

#### äºŒã€æ•°æ®é›†å¤„ç†

æœ¬æ¬¡å®éªŒæˆ‘ä»¬é€‰æ‹©é¢„æµ‹ç”µå½±çš„æ’åºï¼Œä½¿ç”¨åŠ©æ•™ç»™çš„è±†ç“£ç”µå½±è¯„åˆ†æ•°æ®é›† `Movie_score.csv`

é¦–å…ˆæˆ‘ä»¬**å°†ç”µå½±å’Œç”¨æˆ·è¿›è¡Œé‡æ–°ç¼–å·å¤„ç†**ï¼Œå°†ç”¨æˆ·é‡æ–°ç¼–å·ä¸º 0 - 544ï¼Œ0 - 999ï¼Œå°†ç»“æœå­˜åˆ° `New_Movie_score.csv` ä¸­

ç„¶åï¼Œ**æˆ‘ä»¬å°†æ•°æ®é›†æŒ‰æ—¶é—´æˆ³æ’åºï¼Œå¹¶æŒ‰ç…§ 8ï¼š1ï¼š1 çš„æ¯”ä¾‹ï¼Œåˆ†è¯è®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†ã€‚**

å…·ä½“å®ç°è§ `stage3/GetData.py` å’Œ `stage3/Dataset.py`

#### ä¸‰ã€MFæ¨¡å‹å®ç°

MF çš„æ¨¡å‹å®ç°å¦‚ä¸‹ï¼š

``` python
class MF(nn.Module):

    def __init__(self, user_num, item_num, mean , embedding_size, dropout):
        """
        	user_num: ç”¨æˆ·æ•°
        	item_num: ç”µå½±æ•°
        	mean: æ‰€æœ‰è¯„åˆ†çš„å¹³å‡åˆ†
        	embedding_size: æ½œåœ¨å› å­æ•°
        	dropout: ä¸¢å¼ƒç‡
        """
        super(MF, self).__init__()
        self.user_emb = nn.Embedding(user_num, embedding_size) # p_u
        self.item_emb = nn.Embedding(item_num, embedding_size) # q_i
        self.user_bias = nn.Embedding(user_num, 1)	# b_u
        self.item_bias = nn.Embedding(item_num, 1)	# b_i

        self.user_emb.weight.data.uniform_(0, 0.005)
        self.item_emb.weight.data.uniform_(0, 0.005)
        self.user_bias.weight.data.uniform_(-0.01, 0.01)
        self.item_bias.weight.data.uniform_(-0.01, 0.01)

        self.mean = nn.Parameter(torch.FloatTensor([mean]), False)
        self.dropout = nn.Dropout(dropout)

    def forward(self, u_id, i_id):
        U = self.user_emb(u_id)	# p_u
        I = self.item_emb(i_id) # q_i
        b_u = self.user_bias(u_id).squeeze()	# b_u
        b_i = self.item_bias(i_id).squeeze()	# b_i
        return self.dropout((U * I).sum(1) + b_u + b_i + self.mean)
```

#### å››ã€è¯„ä¼°

æœ¬æ¬¡å®éªŒä½¿ç”¨ ndcg æ¥è¯„ä¼°æœ€åçš„ç»“æœã€‚å…·ä½“è®¡ç®—æ­¥éª¤å¦‚ä¸‹ï¼š

1. å¯¹äºæµ‹è¯•é›†ä¸­çš„æ¯ä¸ª user, æˆ‘ä»¬å…ˆé¢„æµ‹å®ƒåœ¨æµ‹è¯•é›†ä¸­çš„ item çš„è¯„åˆ†ï¼Œå°†å…¶æŒ‰ç…§è¯„åˆ†æ’åºï¼Œå¾—åˆ° predict_rankï¼Œç”¨å®ƒçš„çœŸå®å¾—åˆ†å’Œé¢„æµ‹çš„æ’åºç»“æœç®—å‡º DCG

2. ç„¶åï¼Œå†å°†è¯¥ user åœ¨æµ‹è¯•é›†ä¸­çš„ item æŒ‰ç…§è¯„åˆ†ç”±é«˜åˆ°ä½æ’åºï¼Œå¾—åˆ° gt_rank, ç”¨å®ƒçš„çœŸå®è¯„åˆ†å’ŒçœŸå®æ’åºè®¡ç®—å‡º iDCG

3. ä¸¤è€…ç›¸é™¤ï¼Œå³å¯ç®—å‡ºè¯¥ item çš„ ndcg

   - ä¾‹å¦‚ï¼Œå¯¹äº user_id = 31 çš„ç”¨æˆ·ï¼Œæˆ‘ä»¬çš„é¢„æµ‹æ’åºæ˜¯ï¼š['126(4)', '299(3)', '3(3)', '981(1)', '676(4)']ï¼Œ DCG = 29.149976941591724
   - çœŸå®æ’åºæ˜¯ï¼š['676(4)', '126(4)', '299(3)', '3(3)', '981(1)']ï¼ŒiDCG = 31.365535017320155
   - è¯¥ç”¨æˆ·çš„ ndcg = DCG / iDCG = 0.9293632939943478

4. æœ€åï¼Œå¯¹äºæ‰€æœ‰ç”¨æˆ·çš„ ndcg æ±‚å¹³å‡ï¼Œå³æ˜¯æœ€çš„ ndcgã€‚

   ç‰¹åˆ«çš„ï¼Œå¯¹äºåœ¨æµ‹è¯•é›†ä¸­æ²¡æœ‰ item çš„ç”¨æˆ·ï¼Œæˆ‘ä»¬ç›´æ¥å°†å…¶å¿½ç•¥ï¼Œä¸è®¡ç®—ä»–çš„ ndcgã€‚

å…·ä½“å®ç°å¦‚ä¸‹:

``` python
def metrics(model, evaluate_set:dict):
    """
        evaluate_set æ˜¯ä¸€ä¸ªåˆ—è¡¨,æ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªå­—å…¸,å­˜äº† ç”µå½±ID->è¯„åˆ†
    """
    NDCG = 0
    count = 0
    for user_id, item_dic in enumerate(evaluate_set):
        item_id = list(item_dic.keys())
        user = torch.full((len(item_id),),user_id,dtype=torch.int64).cuda()
        item = torch.tensor(item_id,dtype=torch.int64).cuda()
        prediction = model(user, item).detach().cpu().numpy()[:,np.newaxis]
        temp = np.array(list(item_dic.values()))[:,np.newaxis]
        # rank æ˜¯ä¸€ä¸ªåˆ—è¡¨ [[predict,score],...] æŒ‰ç…§ predict çš„åˆ†æ•°é™åº
        rank = np.concatenate([prediction,temp],axis=1).tolist()
        rank.sort(reverse=True)
        DCG = 0
        for i,(_,score) in enumerate(rank):
            DCG += (2**score - 1) / math.log2(i+2)  # å› ä¸º i ä» 0 å¼€å§‹æ‰€ä»¥é¢å¤–åŠ 1
        iDCG = 0
        iRank = list(item_dic.values())
        iRank.sort(reverse=True)
        for i, score in enumerate(iRank):
            iDCG += (2**score - 1) / math.log2(i+2)
        if iDCG != 0:
            NDCG_i = DCG / iDCG
            NDCG += NDCG_i
            count += 1
    return NDCG / count
```



### ç»“æœåˆ†æ

1. æˆ‘ä»¬è®­ç»ƒäº† 20 ä¸ª ecpoch, å–éªŒè¯é›†é‡Œ ndcg æœ€é«˜çš„æ¨¡å‹ä½œä¸ºæœ€ç»ˆæ¨¡å‹ï¼Œæœ€åå¾—åˆ°çš„ç»“æœå¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œæµ‹è¯•é›†çš„**æœ€ç»ˆçš„ ndcg = 0.844**ï¼š

   ![](figs\result.png)

2. ç„¶åæˆ‘ä»¬æ ¹æ®è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œå°†æ¯ä¸ª user çš„é¢„æµ‹æ’åå’Œå®é™…æ’åå­˜åˆ° `stage3/Data/rank_result.csv` ä¸­ã€‚éƒ¨åˆ†ç»“æœå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š

<img src="C:\Users\peterfang\AppData\Roaming\Typora\typora-user-images\image-20221111201459237.png" alt="image-20221111201459237" style="zoom:50%;" />

- è§‚å¯Ÿæ’åºæ•°æ®ï¼Œæˆ‘ä»¬å‘ç°å¤§éƒ¨åˆ† item çš„æ’åºä½ç½®éƒ½ç›¸å¯¹æ­£ç¡®

- ä½†ä»ç„¶å­˜åœ¨éƒ¨åˆ†æ’åºé¢„æµ‹å®é™…ä¸æ˜¯å¾ˆå¥½ï¼Œæ¯”å¦‚ user_id=18 çš„é¢„æµ‹ç»“æœä¸º['333(4)', '514(5)']ï¼Œç†è®ºä¸Šæ¥è¯´å®ƒç›¸å½“äºå®Œå…¨é”™äº†ã€‚**ä½†æ˜¯ç”±äº item æ•°æ¯”è¾ƒå°‘ï¼Œä»¥åŠ item è¯„åˆ†éƒ½å¾ˆé«˜ï¼Œè¯„åˆ†ç›¸å·®ä¸å¤§ã€‚**æ•…æŒ‰ç…§ä¸Šè¿°ndcgçš„ç®—æ³•ï¼Œå®ƒçš„ ndcg = 0.8540645566659568

- åŒæ—¶å­˜åœ¨åƒ user_id=16 çš„æ•°æ®é‚£æ ·ï¼Œåªæœ‰ä¸€ä¸ª item çš„æƒ…å†µï¼Œè¿™æ ·ä¸ç®¡æ¨¡å‹å¥½åï¼Œå®ƒ ndcg = 1

- æ‰€ä»¥ç®—å‡ºæ¥çš„ ndcg å®é™…ä¸Šæ˜¯è™šé«˜çš„ã€‚å› æ­¤ï¼Œndcg åœ¨æˆ‘ä»¬è¿™ç§åœºæ™¯ä¸‹ï¼Œå¯èƒ½ä¸æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„è¯„ä¼°æ¨¡å‹å¥½åçš„æŒ‡æ ‡ã€‚

  (å½“ç„¶ä¹Ÿå¯èƒ½æ˜¯æˆ‘ä»¬è¿™ç§ ndcg çš„ç®—æ³•æœ‰é—®é¢˜ã€‚ä½†æ˜¯å®éªŒæ–‡æ¡£é‡Œæ²¡æœ‰è¯´æ€ä¹ˆç®—ã€‚æˆ‘ä»¬é—®äº†åŠ©æ•™ï¼ŒåŠ©æ•™è¯´å¯ä»¥è¿™ä¹ˆç®—)

  

## æäº¤æ–‡ä»¶è¯´æ˜

``` bash
â”œâ”€â”€â”€stage1
â”‚   â”‚   catch_book.py	# ä¹¦ç±ä¿¡æ¯çš„çˆ¬å–
â”‚   â”‚   catch_movie.py	# ç”µå½±çš„çˆ¬å–
â”‚   â”‚
â”‚   â””â”€â”€â”€data
â”‚           book.csv	# ä¹¦ç±çˆ¬å–ç»“æœ
â”‚           Book_id.txt	# è¦æ±‚çˆ¬å–çš„ä¹¦ç±id
â”‚           movie.csv	# ç”µå½±çˆ¬å–ç»“æœ
â”‚           Movie_id.txt	# è¦æ±‚çˆ¬å–çš„ç”µå½±id
â”‚
â”œâ”€â”€â”€stage2
â”‚   â”‚   bool_search.py	# å¸ƒå°”æ£€ç´¢
â”‚   â”‚   gen_invert_table.py	# å»ºç«‹å€’æ’è¡¨
â”‚   â”‚   movie_search.py	# ç”¨è‡ªç„¶è¯­è¨€æ¥æœç´¢ç”µå½±
â”‚   â”‚   split_words.py	# åˆ†è¯
â”‚   â”‚   utils.py	# ä¸€äº›è¾…åŠ©å‡½æ•°
â”‚   â”‚
â”‚   â””â”€â”€â”€data
â”‚           book_invert.csv	# ä¹¦ç±çš„å€’æ’è¡¨
â”‚           Book_tag.csv	# ä¹¦ç±çš„tag
â”‚           book_words.csv	# ä¹¦ç±çš„åˆ†è¯ç»“æœ
â”‚           movie_invert.csv	# ç”µå½±çš„å€’æ’è¡¨
â”‚           Movie_tag.csv	# ç”µå½±çš„tag
â”‚           movie_words.csv	# ç”µå½±çš„åˆ†è¯ç»“æœ
â”‚           stopwords.txt	# åœç”¨è¯è¡¨
â”‚           word_dict.pkl	# åˆ†è¯å­—å…¸
â”‚
â””â”€â”€â”€stage3
    â”‚   Dataset.py	# å°†åŸå§‹æ•°æ®åˆ’åˆ†æˆè®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†
    â”‚   Evaluate.py	# è¯„ä¼°æ’åºç»“æœï¼Œè®¡ç®—ndcg
    â”‚   GetData.py	# å°† user_id çš„ movie_id é‡æ’
    â”‚   get_rank_result.py	# é€šè¿‡è®­ç»ƒå¥½çš„æ¨¡å‹å¾—åˆ°æ’åºç»“æœ
    â”‚   Model.py	# MFæ¨¡å‹
    â”‚   train.py	# æ¨¡å‹è®­ç»ƒ
    â”‚
    â”œâ”€â”€â”€Data
    â”‚       Movie_score.csv	# åŸå§‹æ•°æ®
    â”‚       New_Movie_score.csv	# å¤„ç†è¿‡IDçš„æ•°æ®
    â”‚       rank_result.csv	# é¢„æµ‹çš„æµ‹è¯•é›†æ’åºç»“æœ
    â”‚
    â””â”€â”€â”€Model
            MF_DoubanMovie_0.005lr_0dropout_20factornum.pth	# è®­ç»ƒå¥½çš„æ¨¡å‹
```



## å®éªŒå°ç»“

1. é€šè¿‡æœ¬æ¬¡å®éªŒï¼Œæˆ‘ä»¬ç†Ÿæ‚‰äº†çˆ¬è™«çš„ä½¿ç”¨æ–¹æ³•ã€‚
2. é€šè¿‡æœ¬æ¬¡å®éªŒï¼Œæˆ‘ä»¬ç†Ÿæ‚‰äº†å€’æ’è¡¨çš„æ„å»ºï¼Œå¹¶å®ç°äº†ä¸€ä¸ªç®€å•çš„å¸ƒå°”æ£€ç´¢ç³»ç»Ÿã€‚
3. é€šè¿‡æœ¬æ¬¡å®éªŒï¼Œæˆ‘ä»¬ç†Ÿæ‚‰äº†ä¸€äº›æ¨èæ¨¡å‹ã€‚



## å®éªŒå»ºè®®

1. å»ºè®®å®éªŒæ–‡æ¡£é‡Œå¯ä»¥æŠŠå®éªŒè¦æ±‚å†™çš„æ›´æ˜ç¡®ä¸€ç‚¹, æ¯”å¦‚ stage3 çš„æ–‡æ¡£å¯ä»¥æŠŠ ndcg æ€ä¹ˆç®—è¯¦ç»†è§„å®šä¸€ä¸‹ã€‚
2. æ„Ÿè§‰stage3å¯ä»¥æ”¹æˆé¢„æµ‹ç”¨æˆ·å–œæ¬¢çš„ç”µå½± (æµ‹è¯•é›†ä¸­ç”µå½±è¯„åˆ† >= 3çš„å½“æˆæ˜¯å–œæ¬¢)ï¼Œç„¶åå¯¹æ‰€æœ‰éè®­ç»ƒé›†å’ŒéªŒè¯é›†ä¸­çš„ç”µå½±è¿›è¡Œè¯„åˆ†é¢„æµ‹ï¼Œå–å‰10ä¸ªå½“æˆé¢„æµ‹çš„ç”¨æˆ·å–œæ¬¢çš„ç”µå½±ï¼Œç„¶åç”¨ recall@10 å’Œ ndcg@10 å½“æˆè¯„ä»·æŒ‡æ ‡ã€‚è¿™ç§ä»»åŠ¡æ›´åƒæ¨èä»»åŠ¡ã€‚

